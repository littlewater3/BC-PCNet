Pipeline(
  (backbone): KPFCN(
    (encoder_blocks): ModuleList(
      (0): SimpleBlock(
        (KPConv): KPConv(radius: 0.06, extent: 0.05, in_feat: 1, out_feat: 128)
        (batch_norm): BatchNormBlock(in_feat: 128, momentum: 0.020, only_bias: False)
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (1): ResnetBottleneckBlock(
        (unary1): UnaryBlock(in_feat: 128, out_feat: 64, BN: True, ReLU: True)
        (KPConv): KPConv(radius: 0.06, extent: 0.05, in_feat: 64, out_feat: 64)
        (batch_norm_conv): BatchNormBlock(in_feat: 64, momentum: 0.020, only_bias: False)
        (unary2): UnaryBlock(in_feat: 64, out_feat: 256, BN: True, ReLU: False)
        (unary_shortcut): UnaryBlock(in_feat: 128, out_feat: 256, BN: True, ReLU: False)
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (2): ResnetBottleneckBlock(
        (unary1): UnaryBlock(in_feat: 256, out_feat: 64, BN: True, ReLU: True)
        (KPConv): KPConv(radius: 0.06, extent: 0.05, in_feat: 64, out_feat: 64)
        (batch_norm_conv): BatchNormBlock(in_feat: 64, momentum: 0.020, only_bias: False)
        (unary2): UnaryBlock(in_feat: 64, out_feat: 256, BN: True, ReLU: False)
        (unary_shortcut): Identity()
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (3): ResnetBottleneckBlock(
        (unary1): UnaryBlock(in_feat: 256, out_feat: 128, BN: True, ReLU: True)
        (KPConv): KPConv(radius: 0.12, extent: 0.10, in_feat: 128, out_feat: 128)
        (batch_norm_conv): BatchNormBlock(in_feat: 128, momentum: 0.020, only_bias: False)
        (unary2): UnaryBlock(in_feat: 128, out_feat: 512, BN: True, ReLU: False)
        (unary_shortcut): UnaryBlock(in_feat: 256, out_feat: 512, BN: True, ReLU: False)
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (4): ResnetBottleneckBlock(
        (unary1): UnaryBlock(in_feat: 512, out_feat: 128, BN: True, ReLU: True)
        (KPConv): KPConv(radius: 0.12, extent: 0.10, in_feat: 128, out_feat: 128)
        (batch_norm_conv): BatchNormBlock(in_feat: 128, momentum: 0.020, only_bias: False)
        (unary2): UnaryBlock(in_feat: 128, out_feat: 512, BN: True, ReLU: False)
        (unary_shortcut): Identity()
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (5): ResnetBottleneckBlock(
        (unary1): UnaryBlock(in_feat: 512, out_feat: 128, BN: True, ReLU: True)
        (KPConv): KPConv(radius: 0.12, extent: 0.10, in_feat: 128, out_feat: 128)
        (batch_norm_conv): BatchNormBlock(in_feat: 128, momentum: 0.020, only_bias: False)
        (unary2): UnaryBlock(in_feat: 128, out_feat: 512, BN: True, ReLU: False)
        (unary_shortcut): Identity()
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (6): ResnetBottleneckBlock(
        (unary1): UnaryBlock(in_feat: 512, out_feat: 256, BN: True, ReLU: True)
        (KPConv): KPConv(radius: 0.25, extent: 0.20, in_feat: 256, out_feat: 256)
        (batch_norm_conv): BatchNormBlock(in_feat: 256, momentum: 0.020, only_bias: False)
        (unary2): UnaryBlock(in_feat: 256, out_feat: 1024, BN: True, ReLU: False)
        (unary_shortcut): UnaryBlock(in_feat: 512, out_feat: 1024, BN: True, ReLU: False)
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (7): ResnetBottleneckBlock(
        (unary1): UnaryBlock(in_feat: 1024, out_feat: 256, BN: True, ReLU: True)
        (KPConv): KPConv(radius: 0.25, extent: 0.20, in_feat: 256, out_feat: 256)
        (batch_norm_conv): BatchNormBlock(in_feat: 256, momentum: 0.020, only_bias: False)
        (unary2): UnaryBlock(in_feat: 256, out_feat: 1024, BN: True, ReLU: False)
        (unary_shortcut): Identity()
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (8): ResnetBottleneckBlock(
        (unary1): UnaryBlock(in_feat: 1024, out_feat: 256, BN: True, ReLU: True)
        (KPConv): KPConv(radius: 0.25, extent: 0.20, in_feat: 256, out_feat: 256)
        (batch_norm_conv): BatchNormBlock(in_feat: 256, momentum: 0.020, only_bias: False)
        (unary2): UnaryBlock(in_feat: 256, out_feat: 1024, BN: True, ReLU: False)
        (unary_shortcut): Identity()
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (9): ResnetBottleneckBlock(
        (unary1): UnaryBlock(in_feat: 1024, out_feat: 512, BN: True, ReLU: True)
        (KPConv): KPConv(radius: 0.50, extent: 0.40, in_feat: 512, out_feat: 512)
        (batch_norm_conv): BatchNormBlock(in_feat: 512, momentum: 0.020, only_bias: False)
        (unary2): UnaryBlock(in_feat: 512, out_feat: 2048, BN: True, ReLU: False)
        (unary_shortcut): UnaryBlock(in_feat: 1024, out_feat: 2048, BN: True, ReLU: False)
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
      (10): ResnetBottleneckBlock(
        (unary1): UnaryBlock(in_feat: 2048, out_feat: 512, BN: True, ReLU: True)
        (KPConv): KPConv(radius: 0.50, extent: 0.40, in_feat: 512, out_feat: 512)
        (batch_norm_conv): BatchNormBlock(in_feat: 512, momentum: 0.020, only_bias: False)
        (unary2): UnaryBlock(in_feat: 512, out_feat: 2048, BN: True, ReLU: False)
        (unary_shortcut): Identity()
        (leaky_relu): LeakyReLU(negative_slope=0.1)
      )
    )
    (coarse_out): Conv1d(1024, 528, kernel_size=(1,), stride=(1,))
    (coarse_in): Conv1d(528, 1024, kernel_size=(1,), stride=(1,))
    (decoder_blocks): ModuleList(
      (0): NearestUpsampleBlock(layer: 3 -> 2)
      (1): UnaryBlock(in_feat: 3072, out_feat: 1024, BN: True, ReLU: True)
      (2): NearestUpsampleBlock(layer: 2 -> 1)
      (3): UnaryBlock(in_feat: 1536, out_feat: 512, BN: True, ReLU: True)
      (4): NearestUpsampleBlock(layer: 1 -> 0)
      (5): UnaryBlock(in_feat: 768, out_feat: 256, BN: True, ReLU: True)
    )
    (fine_out): Conv1d(256, 264, kernel_size=(1,), stride=(1,))
  )
  (coarse_transformer): RepositioningTransformer(
    (positional_encoding): VolumetricPositionEncoding()
    (layers): ModuleList(
      (0): GeometryAttentionLayer(
        (q_proj): Linear(in_features=528, out_features=528, bias=False)
        (k_proj): Linear(in_features=528, out_features=528, bias=False)
        (v_proj): Linear(in_features=528, out_features=528, bias=False)
        (merge): Linear(in_features=528, out_features=528, bias=False)
        (mlp): Sequential(
          (0): Linear(in_features=1056, out_features=1056, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=1056, out_features=528, bias=False)
        )
        (norm1): LayerNorm((528,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((528,), eps=1e-05, elementwise_affine=True)
      )
      (1): GeometryAttentionLayer(
        (q_proj): Linear(in_features=528, out_features=528, bias=False)
        (k_proj): Linear(in_features=528, out_features=528, bias=False)
        (v_proj): Linear(in_features=528, out_features=528, bias=False)
        (merge): Linear(in_features=528, out_features=528, bias=False)
        (mlp): Sequential(
          (0): Linear(in_features=1056, out_features=1056, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=1056, out_features=528, bias=False)
        )
        (norm1): LayerNorm((528,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((528,), eps=1e-05, elementwise_affine=True)
      )
      (2): ModuleList(
        (0): Matching(
          (src_proj): Linear(in_features=528, out_features=528, bias=False)
          (tgt_proj): Linear(in_features=528, out_features=528, bias=False)
        )
        (1): SoftProcrustesLayer()
      )
      (3): GeometryAttentionLayer(
        (q_proj): Linear(in_features=528, out_features=528, bias=False)
        (k_proj): Linear(in_features=528, out_features=528, bias=False)
        (v_proj): Linear(in_features=528, out_features=528, bias=False)
        (merge): Linear(in_features=528, out_features=528, bias=False)
        (mlp): Sequential(
          (0): Linear(in_features=1056, out_features=1056, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=1056, out_features=528, bias=False)
        )
        (norm1): LayerNorm((528,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((528,), eps=1e-05, elementwise_affine=True)
      )
      (4): GeometryAttentionLayer(
        (q_proj): Linear(in_features=528, out_features=528, bias=False)
        (k_proj): Linear(in_features=528, out_features=528, bias=False)
        (v_proj): Linear(in_features=528, out_features=528, bias=False)
        (merge): Linear(in_features=528, out_features=528, bias=False)
        (mlp): Sequential(
          (0): Linear(in_features=1056, out_features=1056, bias=False)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=1056, out_features=528, bias=False)
        )
        (norm1): LayerNorm((528,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((528,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (coarse_matching): Matching(
    (src_proj): Linear(in_features=528, out_features=528, bias=False)
    (tgt_proj): Linear(in_features=528, out_features=528, bias=False)
  )
  (soft_procrustes): SoftProcrustesLayer()
)